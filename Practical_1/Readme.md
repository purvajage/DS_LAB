# Practical 1 - Data Preprocessing in Python

## ğŸ¯ Objective
To preprocess (Imputation, Label Encoding, and Data Cleaning) and prepare data using NumPy and Pandas in Python for effective analysis and modeling.

This practical focuses on cleaning and transforming real-world datasets to ensure they are ready for machine learning and statistical analysis.

---

## ğŸ“ Contents

### 1. `titanic.ipynb`
- **Dataset**: Titanic Dataset
- **Operations Performed**:
  - Handling missing values (e.g., Age)
  - One hot Encoding of categorical variables (e.g., Sex, Embarked)
  - Data Cleaning and basic EDA using Pandas

### 2. `heartfailureprediction.ipynb`
- **Dataset**: [Heart Failure Prediction Dataset (Kaggle)](https://www.kaggle.com/datasets/fedesoriano/heart-failure-prediction)
- **Operations Performed**:
  - Detection and imputation of null values
  - Label Encoding of binary/categorical features

### 3. `employee_promotion.ipynb`
- **Dataset**: Employee Promotion Dataset
- **Operations Performed**:
  - Handling missing values in education and previous_year_rating
  - Label Encoding of  categorical variables
  - Data cleanup (removal of irrelevant columns, outlier checks)
 
---

## ğŸ› ï¸ Technologies Used
- Python
- Jupyter Notebook (Google Colab)
- NumPy
- Pandas
- Scikit-learn (for Label Encoding)


---

## ğŸ“Œ How to Run
1. Clone the repository or open the notebooks in [Google Colab](https://colab.research.google.com/).
2. Install required packages if running locally.
3. Run each cell step-by-step to see the preprocessing tasks.

---

## ğŸ“š Learning Outcomes
- Learn how to handle missing and inconsistent data.
- Apply label encoding for categorical features.
- Clean real-world datasets and make them ML-ready.
- Use Pandas and NumPy effectively for data wrangling.

---

## ğŸ”— References
- [Titanic Dataset (Kaggle)](https://www.kaggle.com/competitions/titanic)
- [Heart Failure Prediction Dataset](https://www.kaggle.com/datasets/fedesoriano/heart-failure-prediction)


---

